{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import csv\n",
    "from numpy import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import date\n",
    "# Special imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max 306 Min 27\n"
     ]
    }
   ],
   "source": [
    "# We have downloaded this Excel file and reformatted it into a more parseable form\n",
    "f = open(\"./AMP_dataset.txt\", \"r\")\n",
    "store_seq = []\n",
    "seq_length = []\n",
    "output_y = []\n",
    "for x in f:\n",
    "    line = list(x)\n",
    "    store_seq.append(line[0:len(line)-3])\n",
    "    output_y.append(int(line[-2]))\n",
    "    seq_length.append(int(len(line)-3))\n",
    "    # print(line[0:len(line)-3])\n",
    "\n",
    "sequence = np.zeros((len(store_seq), max(seq_length)), dtype=object)\n",
    "\n",
    "for i in range(len(store_seq)):\n",
    "    sequence[i,0:seq_length[i]] = store_seq[i]\n",
    "\n",
    "print('Max', max(seq_length), 'Min', min(seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting to OHE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique amino acids are 5\n"
     ]
    }
   ],
   "source": [
    "# # different amino acids\n",
    "amino_acid = ['A', 'T','G','C', 'X'] # X is the undetermined amino acid, so total length is 21\n",
    "print('Number of unique amino acids are', np.shape(np.unique(amino_acid))[0])\n",
    "\n",
    "np.save('../model/categorical_variables', amino_acid)\n",
    "\n",
    "def onehotseq(sequence):\n",
    "  seq_len = len(sequence)\n",
    "  seq_en = np.zeros(( seq_len, np.shape(amino_acid)[0]))\n",
    "  for i in range(seq_len):\n",
    "    if (sequence[i] in amino_acid):\n",
    "      pos = amino_acid.index(sequence[i])\n",
    "      seq_en[i,pos] = 1     \n",
    "    # else:\n",
    "    #   pos = amino_acid.index('X')\n",
    "    #   seq_en[i,pos] = 1\n",
    "  return seq_en\n",
    "\n",
    "### input sequence data\n",
    "def one_hot_encoding(input_sequence, seq_length):\n",
    "    ohe = np.zeros((input_sequence.shape[0], max(seq_length), len(amino_acid)))\n",
    "    for i in range(input_sequence.shape[0]):\n",
    "        seq_len = seq_length[i]\n",
    "        seq_en = onehotseq(input_sequence[i,0:seq_len])\n",
    "        ohe[i,0:seq_len,:] = seq_en\n",
    "    return ohe\n",
    "\n",
    "ohe = one_hot_encoding(sequence, seq_length)\n",
    "seq_length = np.array(seq_length).reshape((len(seq_length),))\n",
    "output_y = np.array(output_y).reshape((len(output_y),))\n",
    "\n",
    "\n",
    "# idx = (seq_length>120)\n",
    "# ohe = ohe[idx]\n",
    "# seq_length = seq_length[idx]\n",
    "# output_y = output_y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below we are randomly choosing 1000 training, 100 test and valid examples. This is for showing interpretability quickly. \n",
    "#### feel free to keep all the data for interpretability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples (5200, 306, 5)\n",
      "100 1000 100\n",
      "Mut 1000\n"
     ]
    }
   ],
   "source": [
    "## Split the train and test\n",
    "print('Total examples', ohe.shape)\n",
    "x = np.arange(ohe.shape[0])\n",
    "y = x \n",
    "X, x_test, Y, y_test = train_test_split( x, y, test_size=0.1923, random_state=10) ##[10,20,30]\n",
    "x_train, x_valid, y_train, y_valid = train_test_split( X, Y, test_size=0.23809, random_state=10)\n",
    "\n",
    "x_mut = x_test.copy()\n",
    "_, x_test, _, _ = train_test_split( x_test, x_test, test_size=0.1, random_state=30) ##[10,20,30]\n",
    "_, x_train, _, _ = train_test_split( x_train, x_train, test_size=0.3125, random_state=10) ##[10,20,30]\n",
    "_, x_valid, _, _ = train_test_split( x_valid, x_valid, test_size=0.1, random_state=10) ##[10,20,30]\n",
    "\n",
    "print(len(x_test), len(x_train), len(x_valid))\n",
    "print('Mut', len(x_mut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 306, 5) (1000,) (1000,)\n",
      "(100, 306, 5) (100,) (100,)\n",
      "(100, 306, 5) (100,) (100,)\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "np.save('./x_train', ohe[x_train])\n",
    "np.save('./len_train', seq_length[x_train])\n",
    "np.save('./y_train', output_y[x_train])\n",
    "\n",
    "np.save('./x_valid', ohe[x_valid])\n",
    "np.save('./len_valid', seq_length[x_valid])\n",
    "np.save('./y_valid', output_y[x_valid])\n",
    "\n",
    "np.save('./x_test', ohe[x_test])\n",
    "np.save('./len_test', seq_length[x_test])\n",
    "np.save('./y_test', output_y[x_test])\n",
    "      \n",
    "print(ohe[x_train].shape, seq_length[x_train].shape, output_y[x_train].shape)\n",
    "print(ohe[x_valid].shape, seq_length[x_valid].shape, output_y[x_valid].shape) \n",
    "print(ohe[x_test].shape, seq_length[x_test].shape, output_y[x_test].shape) \n",
    "\n",
    "print(np.sum(output_y[x_test]))\n",
    "# np.save('./store_data/x_train', ohe[x_train])\n",
    "# np.save('./store_data/len_train', seq_length[x_train])\n",
    "# np.save('./store_data/y_train', output_y[x_train])\n",
    "\n",
    "# np.save('./store_data/x_valid', ohe[x_valid])\n",
    "# np.save('./store_data/len_valid', seq_length[x_valid])\n",
    "# np.save('./store_data/y_valid', output_y[x_valid])\n",
    "\n",
    "# np.save('./store_data/x_test', ohe[x_test])\n",
    "# np.save('./store_data/len_test', seq_length[x_test])\n",
    "# np.save('./store_data/y_test', output_y[x_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
